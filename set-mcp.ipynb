{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Joft2qcYsDo"
      },
      "source": [
        "# OLLAMA server on google COLAB\n",
        "\n",
        "This project servers as an Ollama server on google Colab and utilizes ngrok to expose the endpoint.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHP_08IF-8_8"
      },
      "source": [
        "## Step 1: Installing ollama\n",
        "It provides a simple API for creating, running, and managing models, as well as a library of pre-built models\n",
        "\n",
        "https://ollama.com/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25-0au_X1aqv"
      },
      "outputs": [],
      "source": [
        "!curl https://ollama.ai/install.sh | sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYkhRjhx_F4H"
      },
      "source": [
        "## Step 2: Installing ngrok\n",
        "\n",
        "### Download:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNYfWAAu2NGe"
      },
      "outputs": [],
      "source": [
        "!wget https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cFDYwIQ_wjV"
      },
      "source": [
        "### Extract the bin file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzkwuFOl2mLa"
      },
      "outputs": [],
      "source": [
        "!tar xvzf ngrok-v3-stable-linux-amd64.tgz ngrok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJNBtefI_5LR"
      },
      "source": [
        "### Set the auth token\n",
        "\n",
        "a ngrok auth token must be aquired in order to use it.  \n",
        "\n",
        "Follow the instruction below:  \n",
        "https://ngrok.com/docs/getting-started/  \n",
        "\n",
        "Then replace your AuthToken with `<NGROK_AUTH_TOKEN>` below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyVtjdHN2rBS"
      },
      "outputs": [],
      "source": [
        "!./ngrok authtoken <NGROK_AUTH_TOKEN>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBBM9_aTEpxR"
      },
      "source": [
        "## Final Step: Start ollama, pull llama model and stablish ngrok token\n",
        "\n",
        "After pulling the selected model (in this example llama3) an endpoint will be created which can be used to access to ollama api.   \n",
        "**You can also find the endpoint inside your ngrok panel: https://dashboard.ngrok.com/cloud-edge/endpoints**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4X4a_EOl3VQe"
      },
      "outputs": [],
      "source": [
        "!ollama serve & ./ngrok http 11434 --host-header=\"localhost:11434\" --log stdout & sleep 5s && ollama run llama3"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "nBBM9_aTEpxR"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}